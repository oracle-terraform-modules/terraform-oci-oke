= Instructions
:idprefix:
:idseparator: -
:sectlinks:
:sectnums:
:toc: auto


:uri-repo: https://github.com/oracle-terraform-modules/terraform-oci-oke

:uri-rel-file-base: link:{uri-repo}/blob/main
:uri-rel-tree-base: link:{uri-repo}/tree/main

:uri-docs: {uri-rel-file-base}/docs

:uri-topology: {uri-docs}/topology.adoc
:uri-changelog: {uri-rel-file-base}/CHANGELOG.adoc
:uri-contribute: {uri-rel-file-base}/CONTRIBUTING.adoc
:uri-contributors: {uri-rel-file-base}/CONTRIBUTORS.adoc

:uri-configuration: {uri-docs}/configuration.adoc
:uri-license: {uri-rel-file-base}/LICENSE.txt
:uri-kubernetes: https://kubernetes.io/
:uri-networks-subnets-cidr: https://erikberg.com/notes/networks.html
:uri-oci: https://cloud.oracle.com/cloud-infrastructure
:uri-oci-documentation: https://docs.cloud.oracle.com/iaas/Content/home.htm
:uri-oci-fss-pvc: https://docs.oracle.com/en-us/iaas/Content/ContEng/Tasks/contengcreatingpersistentvolumeclaim.htm#Provisioning_Persistent_Volume_Claims_on_the_FileStorageService
:uri-oci-instance-principal: https://docs.cloud.oracle.com/iaas/Content/Identity/Tasks/callingservicesfrominstances.htm
:uri-oci-kms: https://docs.cloud.oracle.com/iaas/Content/KeyManagement/Concepts/keyoverview.htm
:uri-oci-loadbalancer-annotations: https://github.com/oracle/oci-cloud-controller-manager/blob/master/docs/load-balancer-annotations.md
:uri-oci-manage-dynamic-groups: https://docs.cloud.oracle.com/iaas/Content/Identity/Tasks/managingdynamicgroups.htm
:uri-oci-manage-policies: https://docs.cloud.oracle.com/iaas/Content/Identity/Tasks/managingpolicies.htm
:uri-oci-ocir: https://docs.cloud.oracle.com/iaas/Content/Registry/Concepts/registryoverview.htm
:uri-oci-load-balancers: https://docs.oracle.com/en-us/iaas/Content/ContEng/Tasks/contengcreatingloadbalancer.htm#Specifyi
:uri-oci-oke-flexible-loadbalancers: https://medium.com/@lmukadam/creating-flexible-oci-load-balancers-with-oke-bd98e0318976
:uri-oci-secret: https://docs.cloud.oracle.com/en-us/iaas/Content/KeyManagement/Tasks/managingsecrets.htm
:uri-oci-authtoken: https://docs.cloud.oracle.com/iaas/Content/Registry/Tasks/registrygettingauthtoken.htm
:uri-oci-waf: https://docs.cloud.oracle.com/en-us/iaas/Content/WAF/Concepts/overview.htm
:uri-oci-waf-certificate: https://docs.cloud.oracle.com/en-us/iaas/Content/WAF/Concepts/gettingstarted.htm#upload
:uri-oci-waf-dns: https://docs.cloud.oracle.com/en-us/iaas/Content/WAF/Concepts/gettingstarted.htm#update
:uri-oci-waf-policy: https://docs.cloud.oracle.com/en-us/iaas/Content/WAF/Concepts/gettingstarted.htm#create
:uri-oci-waf-tutorial: https://www.youtube.com/watch?v=CfoK9JjBxts
:uri-oke: https://docs.cloud.oracle.com/iaas/Content/ContEng/Concepts/contengoverview.htm
:uri-oracle: https://www.oracle.com
:uri-prereqs: {uri-docs}/prerequisites.adoc
:uri-quickstart: {uri-docs}/quickstart.adoc

:uri-terraform: https://www.terraform.io
:uri-terraform-cidrsubnet-desconstructed: http://blog.itsjustcode.net/blog/2017/11/18/terraform-cidrsubnet-deconstructed/
:uri-terraform-oci: https://www.terraform.io/docs/providers/oci/index.html
:uri-terraform-oke-sample: https://github.com/terraform-providers/terraform-provider-oci/tree/master/examples/container_engine
:uri-terraform-options: {uri-docs}/terraformoptions.adoc
:uri-install-kubectl: https://kubernetes.io/docs/tasks/tools/install-kubectl/
:uri-metricserver: https://kubernetes.io/docs/tasks/debug-application-cluster/resource-metrics-pipeline/#metrics-server
:uri-k8s-dashboard: http://localhost:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/
:uri-psp: https://docs.cloud.oracle.com/en-us/iaas/Content/ContEng/Tasks/contengusingpspswithoke.htm#Using_Pod_Security_Polices_with_Container_Engine_for_Kubernetes
:uri-kubernetes-vpa: https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler

== Assumptions

This section assumes you have completed the following:

. all the {uri-prereqs}[prerequisites]
. all the required {uri-configuration}[configuration]

== KMS Integration

== OKE Variables

If you wish to use {uri-oci-kms}[OCI KMS] to encrypt Kubernetes secrets, the following is required:

* the Terraform user must have the following rights
** {uri-oci-manage-dynamic-groups}[manage dynamic groups]
** {uri-oci-manage-policies}[manage policies in root tenancy]
* link:#adding-the-bastion-host[bastion must be enabled]
* link:#enabling-instance_principal-on-the-operator-host[operator instance_principal must be enabled]
* use_cluster_encryption must be set to _true_
* cluster_kms_key_id must be provided
* create_policies should be set to _true_ if policies for cluster access to KMS are not already in place

If you wish to use {uri-oci-kms}[OCI KMS] to encrypt OKE nodepool boot/block volume, the following is required:

* use_node_pool_volume_encryption must be set to true
* node_pool_volume_kms_key_id must be provided

If you wish to encrypt data in transit between the instance, the boot volume, and the block volumes in OKE node pool.

* enable_pv_encryption_in_transit must be _true_

== Operator Variables

If you wish to use {uri-oci-kms}[OCI KMS] to encrypt operator boot/block volume, the following is required:

* operator_volume_kms_id must be provided

If you wish to encrypt data in transit between the instance, the boot volume, and the block volumes in operator.

* enable_operator_pv_encryption_in_transit must be _true_

== Creating the OKE Cluster

Initialize a working directory containing Terraform configuration files:

----
terraform init
----

Run the plan and apply commands to create OKE cluster and other components.
----
terraform plan
terraform apply
----

You can create a Kubernetes cluster with the latest version of Kubernetes available in OKE using this terraform script. By default the kubernetes_version parameter in terraform.tfvars.example is set as "LATEST". Refer to {uri-terraform-options}#oke[Terraform Options] for other available parameters for OKE.

Use the parameter *cluster_name* to change the name of the cluster as per your needs.

== Using the bastion host
=== Adding the bastion host

If you want to use bastion host, set the parameter *create_bastion_host* to *true* in terraform.tfvars. Refer to {uri-terraform-options}#bastion-host[Bastion Host] for other available bastion related parameters.

****
*Assumption: you have set the create_bastion_host parameter to true in terraform.tfvars*
****

Once the terraform apply is successful you will get the bastion_public_ip as output and also a ssh command. You can also run the below command to get the output:

----
terraform output
----

You can then copy the ssh_to_bastion command, paste and run it in a terminal.

=== Shutting down the bastion host

You can also shutdown the bastion host. Shutting down the bastion host does not destroy it and its public IP address will be preserved. 

To turn off the bastion host, set `bastion_state= "STOPPED"` and run `terraform apply` again.

To turn it on again, set `bastion_state= "RUNNING"` and run `terraform apply` again.

== Using the operator host
=== Adding the operator host

The operator host is used to minimize local dependencies such as oci-cli, kubectl and so on. 

If you want to use the operator host, set the parameter *create_operator* to *true* in terraform.tfvars. Refer to {uri-terraform-options}#operator-host[Admin Host] for other available bastion related parameters.

=== Upgrading the operator host

There is 1 additional parameter for the operator:

* upgrade_operator

_upgrade_operator_ will upgrade the operator compute packages on first boot. 

****
N.B. It is good and recommended practice to upgrade your package host to the latest packages to minimize the possibility of vulnerabilities. However, it will also take slightly longer before the package host is available.
****

Once the terraform apply is successful you will get the operator_private_ip as output and also a ssh command. You can also run the below command to get the output:

----
terraform output
----

You can then copy the ssh_to_operator command, paste and run it in a terminal.

=== Shutting down the operator host

You can also shutdown the operator host. Shutting down the operator host does not destroy it. 

To turn off the operator host, set `operator_state= "STOPPED"` and run `terraform apply` again. 

To turn it on again, set `operator_state= "RUNNING"` and run `terraform apply` again.

=== Using instance_principal on the operator host
==== Enabling instance_principal on the operator host
{uri-oci-instance-principal}[instance_principal] is an IAM service feature that enables instances to be authorized actors (or principals) to perform actions on service resources. Each compute instance has its own identity, and it authenticates using the certificates that are added to it. These certificates are automatically created, assigned to instances and rotated, preventing the need for you to distribute credentials to your hosts and rotate them.

Any user who has access to the instance (who can SSH to the instance), automatically inherits the privileges granted to the instance. Before you enable this feature, ensure that you know who can access it, and that they should be authorized with the permissions you are granting to the instance.

By default, this feature is *_disabled_*. However, it is *_required_* at the time of cluster creation *_if_* you wish to enable link:#kms-integration[KMS Integration], calico, metricserver or creating the OCIR secret.

When you enable this feature, by default, the operator host will have privileges to all resources in the compartment. If you are enabling it for link:#kms-integration[KMS Integration], the operator host will also have rights to create policies in the root tenancy. 

You can also turn on and off the feature at any time without impact on the operator or the cluster.

To enable, set enable_operator_instance_principal to true:

----
enable_operator_instance_principal = "true"
----

and verify:

----
oci network vcn list --compartment-id <compartment-id>
----

==== Disabling instance_principal on the operator host

. Set enable_operator_instance_principal to false in terraform.tfvars

+
----
enable_operator_instance_principal = false
----

. Run terraform apply again:

+
----
terraform apply
----

==== Recommendations for using instance_principal

. Do not enable instance_principal if you are not using link:#kms-integration[KMS Integration] or calico
. Enable instance_principal *_if and only if_* you are using link:#kms-integration[KMS Integration], calico, metricserver or creating the OCIR secret.
. Disable instance_principal once the cluster is created

== Interacting with the OKE Cluster

kubectl installed on the operator host by default and the kubeconfig file is set in the default location (~/.kube/config) so you don't need to set the KUBECONFIG environment variable every time you log in to the operator host. 

****
N.B. In order for kubeconfig to be created on the operator host, you need to link:#enabling-instance_principal-on-the-operator-host[enable instance_principal on the operator host].
****

An alias "*k*" will be created for kubectl on the operator host. 

If you would like to use kubectl locally, {uri-install-kubectl}[install kubectl]. Then, set the KUBECONFIG to the config file path.

----
export KUBECONFIG=path/to/kubeconfig
----

To be able to get the kubeconfig file, you will need to get the credentials with terraform and store in the preferred storage format (e.g: file, vault, bucket...). Example:

[source,hcl]
----
# OKE cluster creation.
module "oke_my_cluster" {
#...
}

# Obtain cluster Kubeconfig.
data "oci_containerengine_cluster_kube_config" "kube_config" {
  cluster_id = module.oke_my_cluster.cluster_id
}

# Store kubeconfig in vault.
resource "vault_generic_secret" "kube_config" {
  path = "my/cluster/path/kubeconfig"
  data_json = jsonencode({
    "data" : data.oci_containerengine_cluster_kube_config.kube_config.content
  })
}

# Store kubeconfig in file.
resource "local_file" "kube_config" {
  content         = data.oci_containerengine_cluster_kube_config.kube_config.content
  filename        = "/tmp/kubeconfig"
  file_permission = "0600"
}
----


****
*Ensure you install the same kubectl version as the OKE Kubernetes version for compatibility.*
****


== Creating a Secret for OCIR

{uri-oci-ocir}[Oracle Cloud Infrastructure Registry] is a highly available private container registry service for storing and sharing container images within the same regions as the OKE Cluster. Use the following rules to determine if you need to create a Kubernetes Secret for OCIR:

* If your container repository is public, you do not need to create a secret. 
* If your container repository is private, you need to create a secret before OKE can pull your images from the private repository. 

If you plan on creating a Kubernetes Secret for OCIR, you must first {uri-oci-authtoken}[create an Auth Token]. Copy and temporarily save the value of the Auth Token.

You must then {uri-oci-secret}[create a Secret in OCI Vault to store] the value of the Auth Token in it. 

Finally, assign the Secret OCID to *secret_id* in terraform.tfvars. Refer to {uri-terraform-options}#ocir[OCIR parameters] for other parameters to be set.

== Installing Calico 

Calico enables network policy in Kubernetes clusters. To install calico set the parameter *enable_calico = true* in terraform.tfvars. By default its set to false. Refer to {uri-terraform-options}#calico[Calico parameters] for other available parameters.

== Installing Kubernetes Metrics Server

{uri-metricserver}[Kubernetes Metrics Server] can be installed by setting the parameter *enable_metric_server = true* in terraform.tfvars. By default, the latest version is installed in kube-system namespace. This is required if you need to use Horizontal Pod Autoscaling.

== Installing Vertical Pod Autoscaler

{uri-kubernetes-vpa}[Vertical Pod Autoscaler] can be installed by configuring the `vpa` parameter:

`vpa = {
  enabled = true,
  version = 0.8
}`

NOTE: Installing the Vertical Pod Autoscaler also requires installing the Metrics Server, so you need to enable that too.

== Scaling the node pools

There are 2 ways you can scale the node pools:

* add more node pools
* increase the number of workers in a subnet per node pool.

Node pools can be added and removed, their size and boot volume size can be updated as well. After each change, run ```terraform apply```. 

Scaling changes to the number and size of node pools are immediate after changing the parameters and running ```terraform apply```. The changes to boot volume size will only be effective in newly created nodes _after_ the change is completed.

Set the parameter *node_pools* to the desired quantities to scale the node pools accordingly. Refer to {uri-topology}#node-pools[Nodepool].

== Accessing the Kubernetes dashboard

By default, the Kubernetes dashboard is now disabled. To enable it, set the *dashboard_enabled = true* _before_ creating the cluster. The dashboard will then be deployed.

In a terminal window, run the command:

----
kubectl proxy
----

Open a browser and go to {uri-k8s-dashboard}[Kubernetes Dashboard] to display the Kubernetes Dashboard.

== Destroying the cluster

Run the below command to destroy the infrastructure created by terraform:

----
terraform destroy
----

****
*Only infrastructure created by terraform will get destroyed.*
****


== Creating a service account for CI/CD tools

OKE now uses Kubeconfig v2 which means the default token has a limited lifespan. In order to allow CI/CD tools to deploy to OKE, a service account must be created.

Set the *create_service_account = true* and you can name the other parameters as appropriate:

----
create_service_account = true

service_account_name = "kubeconfigsa"

service_account_namespace = "kube-system"

service_account_cluster_role_binding = ""
----

== Enabling WAF

You can monitor and protect the load balancers created by OKE using {uri-oci-waf}[OCI Web Application Firewall].

If you would like to monitor and protect your application with OCI Web Application firewall, set `enable_waf = true` *_after_* the cluster has been created. In other words, you need to run `terraform apply` twice. In the first `terraform apply`, `enable_waf` should be set to `false` while the VCN and other resources are created. You can then set `enable_waf=true` and run `terraform apply` again.

You will then need to:

. add the WAF NSG to the load balancer. Refer to the example in {uri-topology}#using-public-load-balancers[Topology - Using Public Load Balancers] for an example
. {uri-oci-waf-policy}[create a WAF Policy]
. {uri-oci-waf-dns}[Update your DNS records to enable WAF]

You may also need to {uri-oci-waf-certificate}[upload your certificate and key].

Follow this {uri-oci-waf-tutorial}[tutorial] on WAF to configure your policy and update your DNS record.

****
N.B. 

. It is good and recommended practice to monitor and protect your application using WAF.
. WAF protection currently only works if you use a public load balancer as a front end to your services. This means that services deployed as NodePort services are currently *not protected* by WAF.
****

== Enabling PodSecurityPolicy

If you would like to enable the PodSecurityPolicy Admission Controller, set 

[source]
admission_controller_options = {
  PodSecurityPolicy = true
}

Ensure you also read {uri-psp}[the documentation] before enabling it. 

****
N.B. This field is updatable. You can set to `true` and `false` and run terraform apply again.
****

== Using Dynamic and Flexible Load Balancers

When you create a service of type LoadBalancer, by default, an OCI Load Balancer with dynamic shape 100Mbps will be created.

You can override this shape by using the {uri-oci-loadbalancer-annotations}[OCI Load Balancer Annotations]. In order to keep using the dynamic shape but change the available total bandwidth to 400Mbps, use the following annotation on your LoadBalancer service:

`service.beta.kubernetes.io/oci-load-balancer-shape: "400Mbps"`

You can also change the shape to flexible and set a minimum and maximum bandwidth:

```
service.beta.kubernetes.io/oci-load-balancer-shape: "flexible"
service.beta.kubernetes.io/oci-load-balancer-shape-flex-min: 50
service.beta.kubernetes.io/oci-load-balancer-shape-flex-max: 200
```

Review the following documentation and articles on creating load balancers of different shapes using Ingress Controllers:

* {uri-oci-load-balancers}[Specifying Alternative Load Balancer Shapes]

* {uri-oci-oke-flexible-loadbalancers}[Creating flexible OCI Load Balancers with OKE]

== Provisioning PVCs on the File Storage Service

. Set `create_fss` to true in terraform.tfvars

+
----
create_fss = false
----

+
It will create the File Storage service instance on a separate subnet with the network security group configured.

+
You can then review the following documentation for creating persistent volume claim and persistent volume using file storage

* {uri-oci-fss-pvc}[Provisioning PV and PVC using FSS]

CAUTION: Running terraform destroy will remove the filesystem storage created using terraform. Ensure you have taken the necessary backup if needed.
